{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoelCanaza/curso-transfer-learning-huggingface/blob/main/my-practice_Computer_vision_con_Hugging_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visi√≥n por computadora con Hugging Face"
      ],
      "metadata": {
        "id": "R3hqYjAtBR9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As√≠ como los modelos basados ‚Äã‚Äãen Transformers han revolucionado el PLN, ahora vemos una explosi√≥n de investigaciones que los aplican a todo tipo de dominios.\n",
        "\n",
        "Uno de los m√°s revolucionarios fue el Vision Transformer (ViT), que fue presentado en junio de 2021 por un equipo de investigadores de Google Brain."
      ],
      "metadata": {
        "id": "ahEndKxpiFBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos el `Trainer` de Hugging Face para entrenar nuestro modelo de clasificaci√≥n de im√°genes.\n",
        "\n",
        "Pero antes tenemos que proporcionarle informaci√≥n sobre nuestros datos, el procesamiento de los datos, el modelo, las m√©tricas e informaci√≥n del entrenamiento.\n",
        "\n",
        "En espec√≠fico necesitamos definir cada uno de estos puntos:\n",
        "\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=prepared_ds[\"train\"],\n",
        "    eval_dataset=prepared_ds[\"validation\"],\n",
        "    tokenizer=feature_extractor\n",
        "\n"
      ],
      "metadata": {
        "id": "GmJtbuL4ia1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesando los datos para visi√≥n\n",
        "\n"
      ],
      "metadata": {
        "id": "PlSO-PzBBp2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos un Dataset del Hub y lo usaremos para afinar un ViT preentrenado con ü§ó `Transformers`."
      ],
      "metadata": {
        "id": "C8Z6pKHuNCXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descargando el dataset"
      ],
      "metadata": {
        "id": "P3JSR8mynNha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos el dataset [beans](https://huggingface.co/datasets/beans). Con base en una imagen de una hoja de frijol buscamos predecir si la hoja est√° saludable o si est√° enferma. El tipo de enfermedad que tiene (Angular Leaf Spot o Bean Rust)."
      ],
      "metadata": {
        "id": "Ay4TKgpriwo7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnkXbvsPBVvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_gSm4h7X8tIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-YOtU_z9GJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Miremos un ejemplo."
      ],
      "metadata": {
        "id": "GXAZcQZLjxyh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMdy9h3YTXjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como en la key `image` tenemos una imagen tipo PIL entonces podemos verla."
      ],
      "metadata": {
        "id": "EvNlwXQ1kIlM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vIxbNSbs9zcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprendamos un poco m√°s sobre las etiquetas en nuestro Dataset. Por ejemplo, notamos que tenemos tres etiquetas."
      ],
      "metadata": {
        "id": "HoqRyrPClF0b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qJMtL5clsen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El m√©todo `int2str` de una `ClassLabel` nos permite pasar la representaci√≥n en n√∫mero (entero) de la etiqueta y recibir el nombre de la clase."
      ],
      "metadata": {
        "id": "lrpDtX8fmAkk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdqVKCmU-Zp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargando el ViT Feature Extractor\n",
        "\n",
        "Prepararemos estas im√°genes para nuestro modelo.\n",
        "\n",
        "Cuando se entrenan los modelos ViT se aplican transformaciones espec√≠ficas a las im√°genes que se les alimentan. Si usa las transformaciones incorrectas en su imagen, el modelo no entender√° lo que est√° viendo. üñº ‚û°Ô∏è\n",
        "\n",
        "Para asegurarnos de que aplicamos las transformaciones correctas, usaremos un `ViTFeatureExtractor` inicializado con una configuraci√≥n que se guard√≥ junto con el modelo pre-entrenado que planeamos usar. En nuestro caso usaremos el modelo `google/vit-base-patch16-224-in21k`, as√≠ que carguemos su deacture extractor desde el Hub.\n",
        "\n",
        "Un extractor de caracter√≠sticas se encarga de preparar las caracter√≠sticas de los inputs de un modelo.\n"
      ],
      "metadata": {
        "id": "B0R-TW5UB7cY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcb1Hv6TB8s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes ver la configuraci√≥n del extractor imprimi√©ndola."
      ],
      "metadata": {
        "id": "a4p7csNWClBY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtkmDEK3Cn5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para procesar una imagen, simplemente p√°sala a la funci√≥n `call` del extractor. Esto devolver√° un diccionario que contiene valores de pixeles, que es la representaci√≥n num√©rica que se pasar√° al modelo.\n",
        "\n",
        "De forma determinada obtenemos una matriz NumPy, pero si agregamos el argumento `return_tensors='pt'`, obtendremos tensores de PyTorch en su lugar."
      ],
      "metadata": {
        "id": "llISPrTvCyGi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbornJYrDMMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos regresa un diccionario con una sola key."
      ],
      "metadata": {
        "id": "Gdo2HV9aovPv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "By9KtPm3okRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver la forma del tensor de pixeles."
      ],
      "metadata": {
        "id": "hMFIJrc3nDxa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVBxTQrom7R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesando el dataset\n",
        "\n",
        "Ahora podemos leer im√°genes y transformarlas en inputs para nuestro modelo. Escribamos una funci√≥n que juntar√° esos dos pasos. Recuerda que `feature_extractor` retorna un diccionario con la key `pixel_values`. Le sumamos una segunda key con las etiquetas `labels`."
      ],
      "metadata": {
        "id": "VbK3LvUODdzw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hw4gQBbwDx4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As√≠ se ve un ejemplo procesado de esta manera."
      ],
      "metadata": {
        "id": "x2Mz6jiED-Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQKDS7Z4D8ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos llamar a la funci√≥n `map` y aplicar esto a todos los ejemplos a la vez. Pero esto puede ser muy lento, especialmente si usa un dataset m√°s grande.\n",
        "\n",
        "Entonces podemos aplicar una ***transformaci√≥n*** al dataset. Las transformaciones solo se aplican a los ejemplos a medida que los indexamos.\n",
        "\n",
        "Sin embargo, primero deber√° actualizar la √∫ltima funci√≥n para aceptar un batch posiblemente con m√°s de una imagen, ya que eso es lo que espera `ds.with_transform`."
      ],
      "metadata": {
        "id": "R05XIJ1mEU9v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xz1WCTueFu8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes aplicar esto directamente al dataset mediante `ds.with_transform(transform)`"
      ],
      "metadata": {
        "id": "DdJvIbgwF4wK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pkbt0uSGE1w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, cada vez que obtengas un ejemplo del dataset, la transformaci√≥n se aplicar√° en tiempo real."
      ],
      "metadata": {
        "id": "UVxbkBHtGKJi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0E_WyVyp6Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El tensor `pixel_values` ‚Äã‚Äãresultante tendr√° forma (2, 3, 224, 224) porque pasamos un batch de dos ejemplos."
      ],
      "metadata": {
        "id": "JP7IEIaJIq6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definiendo el data collator"
      ],
      "metadata": {
        "id": "OENVXBrrJDH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Los data collators, o recopiladores de datos, son objetos que forman batches utilizando una lista de ejemplos de nuestros datasets. Para poder generar los batches, los data collators pueden aplicar alg√∫n procesamiento (como padding en los ejemplos con texto).\n",
        "\n",
        "Definimos una funci√≥n, `collate_fn`, que fungir√° como nuestro data collator. Devolver√° un diccionario por cada batch. Recibir√° un batch de datos que luego ser√°n procesadas.\n",
        "\n",
        "Los batches llegan como listas de dicts. Cada dict tiene los `label` y `pixel_values` de sus respectivos ejemplos, por lo que puedes simplemente desempaquetarlos y apilarlos en tensores de batches. `torch.stack` nos permite concatenar (pegar) tensores.\n"
      ],
      "metadata": {
        "id": "uk2Gi5RVJRKE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMpzrobXJGGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento y evaluaci√≥n\n",
        "\n",
        "Definamos el resto de los argumentos necesarios para `Trainer`."
      ],
      "metadata": {
        "id": "lN_nWx45IyqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definiendo la m√©trica"
      ],
      "metadata": {
        "id": "BH3I27nAqgZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De la biblioteca `Datasets` tambi√©n podemos cargar m√©tricas. `accuracy` se puede usar f√°cilmente para comparar las predicciones con las etiquetas originales."
      ],
      "metadata": {
        "id": "UNIOlnyTroiS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2fT9RFI9TwbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurando `Trainer`\n",
        "\n",
        "Carguemos el modelo preentrenado. Agregaremos `num_labels` para que el modelo cree un encabezado de clasificaci√≥n con el n√∫mero correcto de etiquetas. Tambi√©n incluiremos las asignaciones `id2label` y `label2id` para tener etiquetas legibles por humanos en el widget del Hub."
      ],
      "metadata": {
        "id": "0Mwjo_BttGou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "96HS-B2vTy2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo √∫ltimo que se necesita antes de eso es establecer la configuraci√≥n de entrenamiento definiendo `TrainingArguments`.\n",
        "\n",
        "La mayor√≠a de estos se explican por s√≠ mismos, pero uno que es bastante importante aqu√≠ es `remove_unused_columns=False`. Este eliminar√° cualquier funci√≥n que no utilice la funci√≥n de llamada del modelo. De forma predeterminada es True porque, por lo general, es ideal eliminar las columnas de funciones no utilizadas, lo que facilita el desempaquetado de las entradas en la funci√≥n de llamada del modelo. Pero, en nuestro caso, necesitamos las funciones no utilizadas ('imagen' en particular) para crear '`pixel_values`'."
      ],
      "metadata": {
        "id": "pjReFvZUtExS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQ7IGTMHT15w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pasemos todo a `Trainer`."
      ],
      "metadata": {
        "id": "_RrwAIxOuFj7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_m9XrGgLM-Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, definamos nuestro `Trainer`."
      ],
      "metadata": {
        "id": "5OdLJb55JnHF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYDDK7exVd6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento"
      ],
      "metadata": {
        "id": "2b5F16bjwT-H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2W38onQj0DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluaci√≥n"
      ],
      "metadata": {
        "id": "0hHgq69cwiwf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1GID9Pqoj0ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compartimos en el Hub"
      ],
      "metadata": {
        "id": "VEKvp1iswwbk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqcAcb37j1MT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}